{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install SpeechRecognition git+https://github.com/openai/whisper.git transformers pyaudio sentencepiece datasets[audio] ffmpeg-python pydub\n",
    "%apt install libasound2-dev portaudio19-dev libportaudio2 libportaudiocpp0 ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, model='medium', non_english=False, energy_threshold=1000, record_timeout=2, phrase_timeout=3):\n",
    "        self.model = model\n",
    "        self.non_english = non_english\n",
    "        self.energy_threshold = energy_threshold\n",
    "        self.record_timeout = record_timeout\n",
    "        self.phrase_timeout = phrase_timeout\n",
    "\n",
    "args = Args(model='medium', non_english=True, energy_threshold=1000, record_timeout=2, phrase_timeout=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, Audio\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read as wav_read\n",
    "import io\n",
    "import ffmpeg\n",
    "\n",
    "AUDIO_HTML = \"\"\"\n",
    "<script>\n",
    "var my_div = document.createElement(\"DIV\");\n",
    "var my_p = document.createElement(\"P\");\n",
    "var my_btn = document.createElement(\"BUTTON\");\n",
    "var t = document.createTextNode(\"Aperte para iniciar gravação\");\n",
    "\n",
    "my_btn.appendChild(t);\n",
    "//my_p.appendChild(my_btn);\n",
    "my_div.appendChild(my_btn);\n",
    "document.body.appendChild(my_div);\n",
    "\n",
    "var base64data = 0;\n",
    "var reader;\n",
    "var recorder, gumStream;\n",
    "var recordButton = my_btn;\n",
    "\n",
    "var handleSuccess = function(stream) {\n",
    "  gumStream = stream;\n",
    "  var options = {\n",
    "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
    "    mimeType : 'audio/webm;codecs=opus'\n",
    "    //mimeType : 'audio/webm;codecs=pcm'\n",
    "  };\n",
    "  //recorder = new MediaRecorder(stream, options);\n",
    "  recorder = new MediaRecorder(stream);\n",
    "  recorder.ondataavailable = function(e) {\n",
    "    var url = URL.createObjectURL(e.data);\n",
    "    var preview = document.createElement('audio');\n",
    "    preview.controls = true;\n",
    "    preview.src = url;\n",
    "    document.body.appendChild(preview);\n",
    "\n",
    "    reader = new FileReader();\n",
    "    reader.readAsDataURL(e.data);\n",
    "    reader.onloadend = function() {\n",
    "      base64data = reader.result;\n",
    "      //console.log(\"Inside FileReader:\" + base64data);\n",
    "    }\n",
    "  };\n",
    "  recorder.start();\n",
    "  };\n",
    "\n",
    "recordButton.innerText = \"Gravando... Aperte para parar\";\n",
    "\n",
    "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
    "\n",
    "\n",
    "function toggleRecording() {\n",
    "  if (recorder && recorder.state == \"recording\") {\n",
    "      recorder.stop();\n",
    "      gumStream.getAudioTracks()[0].stop();\n",
    "      recordButton.innerText = \"Realizando transcrição\"\n",
    "  }\n",
    "}\n",
    "\n",
    "// https://stackoverflow.com/a/951057\n",
    "function sleep(ms) {\n",
    "  return new Promise(resolve => setTimeout(resolve, ms));\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "//recordButton.addEventListener(\"click\", toggleRecording);\n",
    "recordButton.onclick = ()=>{\n",
    "toggleRecording()\n",
    "\n",
    "sleep(2000).then(() => {\n",
    "  // wait 2000ms for the data to be available...\n",
    "  // ideally this should use something like await...\n",
    "  //console.log(\"Inside data:\" + base64data)\n",
    "  resolve(base64data.toString())\n",
    "\n",
    "});\n",
    "\n",
    "}\n",
    "});\n",
    "\n",
    "</script>\n",
    "\"\"\"\n",
    "\n",
    "def get_audio():\n",
    "  display(HTML(AUDIO_HTML))\n",
    "  data = eval_js(\"data\")\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "\n",
    "  process = (ffmpeg\n",
    "    .input('pipe:0')\n",
    "    .output('pipe:1', format='wav')\n",
    "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
    "  )\n",
    "  output, err = process.communicate(input=binary)\n",
    "\n",
    "  riff_chunk_size = len(output) - 8\n",
    "  # Break up the chunk size into four bytes, held in b.\n",
    "  q = riff_chunk_size\n",
    "  b = []\n",
    "  for i in range(4):\n",
    "      q, r = divmod(q, 256)\n",
    "      b.append(r)\n",
    "\n",
    "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
    "  riff = output[:4] + bytes(b) + output[8:]\n",
    "\n",
    "  return riff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import io\n",
    "import os\n",
    "import speech_recognition as sr\n",
    "import whisper\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "from queue import Queue\n",
    "from tempfile import NamedTemporaryFile\n",
    "from time import sleep\n",
    "from transformers import BarkModel, AutoProcessor\n",
    "\n",
    "# Import additional libraries\n",
    "from pydub import AudioSegment\n",
    "from IPython.display import display, clear_output, Audio\n",
    "\n",
    "def main():\n",
    "    # The last time a recording was retrieved from the queue.\n",
    "    phrase_time = None\n",
    "    # Current raw audio bytes.\n",
    "    last_sample = bytes()\n",
    "    # Thread safe Queue for passing data from the threaded recording callback.\n",
    "    data_queue = Queue()\n",
    "    # We use SpeechRecognizer to record our audio because it can detect when speech ends.\n",
    "    recorder = sr.Recognizer()\n",
    "    recorder.energy_threshold = args.energy_threshold\n",
    "    recorder.dynamic_energy_threshold = False\n",
    "\n",
    "    # Load/Download model\n",
    "    model = args.model\n",
    "    if args.model != \"large\" and not args.non_english:\n",
    "        model = model + \".en\"\n",
    "\n",
    "    speech_model = BarkModel.from_pretrained(\"suno/bark-small\")\n",
    "    processor = AutoProcessor.from_pretrained(\"suno/bark\")\n",
    "\n",
    "    speech_model = speech_model.to(device)\n",
    "\n",
    "    audio_model = whisper.load_model(model).to(device)\n",
    "\n",
    "    record_timeout = args.record_timeout\n",
    "    phrase_timeout = args.phrase_timeout\n",
    "\n",
    "    temp_file = NamedTemporaryFile().name\n",
    "    transcription = ['']\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            data_queue.put(get_audio())\n",
    "\n",
    "            # Concatenate our current audio data with the latest audio data.\n",
    "            while not data_queue.empty():\n",
    "                data = data_queue.get()\n",
    "                last_sample += data\n",
    "\n",
    "            # Write wav data to the temporary file as bytes.\n",
    "            with open(temp_file, 'w+b') as f:\n",
    "                f.write(io.BytesIO(last_sample).read())\n",
    "\n",
    "            # Read the transcription.\n",
    "            result = audio_model.transcribe(temp_file, fp16=torch.cuda.is_available())\n",
    "            text = result['text'].strip()\n",
    "            inputs = processor(text, voice_preset='v2/pt_speaker_8')\n",
    "\n",
    "            speech_output = speech_model.generate(**inputs.to(device))\n",
    "\n",
    "\n",
    "            sampling_rate = speech_model.generation_config.sample_rate\n",
    "            clear_output(wait=True)\n",
    "            display(Audio(speech_output[0].cpu().numpy(), rate=sampling_rate))\n",
    "            last_sample = bytes()  # Reset the audio buffer\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        exit()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
